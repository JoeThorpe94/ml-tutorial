import pandas as pd





# Path of the file to read
train_file_path = '../data/train.csv'

# Fill in the line below to read the file into a variable home_data
home_data = pd.read_csv(train_file_path) 





# Print summary statistics in next line
home_data.describe()


# What is the average lot size (rounded to nearest integer)?
avg_lot_size = home_data.describe()['LotArea'].loc['mean'].round(0)
print(avg_lot_size)

# As of today, how old is the newest home (current year - the date in which it was built)
newest_home_age = 2024 - home_data.describe()['YearBuilt'].loc['max'].round(0)
print(newest_home_age)








home_data.columns


y = home_data.SalePrice





# Create the list of features below
feature_names = ["LotArea", "YearBuilt", "1stFlrSF", "2ndFlrSF",
                      "FullBath", "BedroomAbvGr", "TotRmsAbvGrd"]
# Select data corresponding to features in feature_names
X=home_data[feature_names]





from sklearn.tree import DecisionTreeRegressor
#specify the model. 
#For model reproducibility, set a numeric value for random_state when specifying the model
home_model = DecisionTreeRegressor(random_state=1)

# Fit the model
home_model.fit(X, y)





predictions = home_model.predict(X)
print(predictions)





# You can write code in this cell
y.head()





# Import the train_test_split function and uncomment
from sklearn.model_selection import train_test_split

# fill in and uncomment
train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)





# Specify the model
home_model = DecisionTreeRegressor(random_state=1)

# Fit home_model with the training data.
home_model.fit(train_X, train_y)





# Predict with all validation observations
val_predictions = home_model.predict(val_X)


# print the top few validation predictions
print(val_predictions[:5])
# print the top few actual prices from validation data
print(val_y.head())





from sklearn.metrics import mean_absolute_error
val_mae = mean_absolute_error(val_y, val_predictions)

print(val_mae)








#Lets compress our previous code into a function
def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):
    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)
    model.fit(train_X, train_y)
    preds_val = model.predict(val_X)
    mae = mean_absolute_error(val_y, preds_val)
    return(mae)


candidate_max_leaf_nodes = [5, 25, 50, 100, 250, 500]
# Write loop to find the ideal tree size from candidate_max_leaf_nodes
scores = {leaf_size: get_mae(leaf_size, train_X, val_X, train_y, val_y) for leaf_size in candidate_max_leaf_nodes}
best_tree_size = min(scores, key=scores.get)

print(scores)
print(best_tree_size)





# Fit the model with best_tree_size. Fill in argument to make optimal size
final_model = DecisionTreeRegressor(max_leaf_nodes=best_tree_size, random_state=1)

# fit the final model
final_model.fit(X, y)





from sklearn.ensemble import RandomForestRegressor

rf_model = RandomForestRegressor()

# fit your model
rf_model.fit(train_X, train_y)

# Calculate the mean absolute error of your Random Forest model on the validation data
rf_val_predictions = rf_model.predict(val_X)
rf_val_mae = mean_absolute_error(rf_val_predictions, val_y)

print("Validation MAE for Random Forest Model: {}".format(rf_val_mae))






